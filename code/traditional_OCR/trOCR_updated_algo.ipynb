{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "5136bbb7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5136bbb7",
        "outputId": "a143513f-462b-4553-9f5b-31e049fc651c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.16.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (0.23.0+cu126)\n",
            "Requirement already satisfied: transformers>=4.30.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (4.57.1)\n",
            "Requirement already satisfied: accelerate>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (1.11.0)\n",
            "Requirement already satisfied: sentencepiece>=0.1.98 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (0.2.1)\n",
            "Requirement already satisfied: tokenizers>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (0.22.1)\n",
            "Requirement already satisfied: Pillow>=9.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 15)) (11.3.0)\n",
            "Requirement already satisfied: opencv-python>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 16)) (4.12.0.88)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 17)) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.24.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 18)) (2.0.2)\n",
            "Requirement already satisfied: PyMuPDF>=1.22.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 21)) (1.26.6)\n",
            "Requirement already satisfied: pdf2image>=1.16.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 22)) (1.17.0)\n",
            "Requirement already satisfied: python-docx>=0.8.11 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 23)) (1.2.0)\n",
            "Requirement already satisfied: jiwer>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 26)) (4.0.0)\n",
            "Requirement already satisfied: rouge-score>=0.1.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 27)) (0.1.2)\n",
            "Requirement already satisfied: bert-score>=0.3.11 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 28)) (0.3.13)\n",
            "Requirement already satisfied: sacrebleu>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 29)) (2.5.1)\n",
            "Requirement already satisfied: nltk>=3.8.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 30)) (3.9.1)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 33)) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 36)) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 7)) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 7)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 7)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 7)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 7)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 7)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 7)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 7)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 7)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 7)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 7)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 7)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 7)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 7)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 7)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 7)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 7)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 7)) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 7)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 7)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 7)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.1.0->-r requirements.txt (line 7)) (3.4.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.30.0->-r requirements.txt (line 9)) (0.36.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.30.0->-r requirements.txt (line 9)) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.30.0->-r requirements.txt (line 9)) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.30.0->-r requirements.txt (line 9)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers>=4.30.0->-r requirements.txt (line 9)) (2.32.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.30.0->-r requirements.txt (line 9)) (0.6.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.20.0->-r requirements.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 17)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 17)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 17)) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 17)) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 17)) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 17)) (2.9.0.post0)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from python-docx>=0.8.11->-r requirements.txt (line 23)) (5.4.0)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.12/dist-packages (from jiwer>=3.0.0->-r requirements.txt (line 26)) (8.3.0)\n",
            "Requirement already satisfied: rapidfuzz>=3.9.7 in /usr/local/lib/python3.12/dist-packages (from jiwer>=3.0.0->-r requirements.txt (line 26)) (3.14.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge-score>=0.1.2->-r requirements.txt (line 27)) (1.4.0)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge-score>=0.1.2->-r requirements.txt (line 27)) (1.17.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.12/dist-packages (from sacrebleu>=2.3.1->-r requirements.txt (line 29)) (3.2.0)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.12/dist-packages (from sacrebleu>=2.3.1->-r requirements.txt (line 29)) (0.9.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.12/dist-packages (from sacrebleu>=2.3.1->-r requirements.txt (line 29)) (0.4.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>=3.8.1->-r requirements.txt (line 30)) (1.5.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 33)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 33)) (2025.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.30.0->-r requirements.txt (line 9)) (1.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.1.0->-r requirements.txt (line 7)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.1.0->-r requirements.txt (line 7)) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.30.0->-r requirements.txt (line 9)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.30.0->-r requirements.txt (line 9)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.30.0->-r requirements.txt (line 9)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.30.0->-r requirements.txt (line 9)) (2025.10.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b360edba",
      "metadata": {
        "id": "b360edba"
      },
      "source": [
        "# IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "3aaf7635",
      "metadata": {
        "id": "3aaf7635"
      },
      "outputs": [],
      "source": [
        "#IMPORTS\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
        "from jiwer import wer, cer\n",
        "from pdf2image import convert_from_path\n",
        "import docx\n",
        "import torch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "356d4023",
      "metadata": {
        "id": "356d4023"
      },
      "source": [
        "# STEP 1: Preprocess scanned page"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "25cfbb0e",
      "metadata": {
        "id": "25cfbb0e"
      },
      "outputs": [],
      "source": [
        "# ------------------------------------------------------\n",
        "# STEP 1: Preprocess scanned page\n",
        "# ------------------------------------------------------\n",
        "def preprocess_image(pil_image):\n",
        "    \"\"\"Preprocess scanned handwritten page: grayscale, normalize illumination, threshold.\"\"\"\n",
        "    img = np.array(pil_image.convert(\"RGB\"))\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    # Normalize illumination using morphological closing\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 15))\n",
        "    bg = cv2.morphologyEx(gray, cv2.MORPH_CLOSE, kernel)\n",
        "    norm = cv2.divide(gray, bg, scale=255)\n",
        "\n",
        "    # Adaptive threshold\n",
        "    binary = cv2.adaptiveThreshold(norm, 255, cv2.ADAPTIVE_THRESH_MEAN_C,\n",
        "                                   cv2.THRESH_BINARY_INV, 25, 15)\n",
        "\n",
        "    # Denoise small specks\n",
        "    binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, np.ones((2, 2), np.uint8))\n",
        "    return binary"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afe8ee81",
      "metadata": {
        "id": "afe8ee81"
      },
      "source": [
        "# STEP 2: Line segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "7b21bc2f",
      "metadata": {
        "id": "7b21bc2f"
      },
      "outputs": [],
      "source": [
        "# ------------------------------------------------------\n",
        "# STEP 2: Line segmentation\n",
        "# ------------------------------------------------------\n",
        "def segment_lines(binary_img, min_height=20):\n",
        "    \"\"\"Segment text lines from binary image.\"\"\"\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (100, 3))\n",
        "    dilated = cv2.dilate(binary_img, kernel, iterations=1)\n",
        "\n",
        "    contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    lines = []\n",
        "    for cnt in sorted(contours, key=lambda x: cv2.boundingRect(x)[1]):\n",
        "        x, y, w, h = cv2.boundingRect(cnt)\n",
        "        if h > min_height:\n",
        "            line = binary_img[y:y + h, x:x + w]\n",
        "            lines.append(line)\n",
        "    return lines"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89f8f4d1",
      "metadata": {
        "id": "89f8f4d1"
      },
      "source": [
        "# STEP 3: Visualize segmented lines (optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "27f967ac",
      "metadata": {
        "id": "27f967ac"
      },
      "outputs": [],
      "source": [
        "# ------------------------------------------------------\n",
        "# STEP 3: Visualize segmented lines (optional)\n",
        "# ------------------------------------------------------\n",
        "def visualize_lines(lines, max_lines=5):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for i, l in enumerate(lines[:max_lines]):\n",
        "        plt.subplot(max_lines, 1, i + 1)\n",
        "        plt.imshow(255 - l, cmap='gray')\n",
        "        plt.axis('off')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3b02a57",
      "metadata": {
        "id": "c3b02a57"
      },
      "source": [
        "# STEP 4: Initialize TrOCR model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "44cb61de",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44cb61de",
        "outputId": "fc897a64-f777-4f9d-c111-9cbf6a7ff54a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# ------------------------------------------------------\n",
        "# STEP 4: Initialize TrOCR model\n",
        "# ------------------------------------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
        "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-handwritten\").to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d66769b",
      "metadata": {
        "id": "4d66769b"
      },
      "source": [
        "# STEP 5: Recognize a single line"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "8aa70add",
      "metadata": {
        "id": "8aa70add"
      },
      "outputs": [],
      "source": [
        "# ------------------------------------------------------\n",
        "# STEP 5: Recognize a single line\n",
        "# ------------------------------------------------------\n",
        "def recognize_line(line_img):\n",
        "    \"\"\"Recognize handwritten text line using TrOCR.\"\"\"\n",
        "    image = Image.fromarray(255 - line_img).convert(\"RGB\")  # invert for TrOCR\n",
        "    pixel_values = processor(images=image, return_tensors=\"pt\").pixel_values.to(device)\n",
        "    generated_ids = model.generate(pixel_values)\n",
        "    text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "    return text.strip()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02a51eb9",
      "metadata": {
        "id": "02a51eb9"
      },
      "source": [
        "# STEP 6: Process a full PDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "a1b068c5",
      "metadata": {
        "id": "a1b068c5"
      },
      "outputs": [],
      "source": [
        "# ------------------------------------------------------\n",
        "# STEP 6: Process a full PDF\n",
        "# ------------------------------------------------------\n",
        "def recognize_pdf(pdf_path, dpi=300):\n",
        "    \"\"\"Convert PDF to images, preprocess, segment, recognize each page.\"\"\"\n",
        "    pages = convert_from_path(pdf_path, dpi=dpi)\n",
        "    all_page_texts = []\n",
        "\n",
        "    for i, page in enumerate(pages, 1):\n",
        "        print(f\"\\nðŸ“„ Processing Page {i}/{len(pages)} ...\")\n",
        "        binary = preprocess_image(page)\n",
        "        lines = segment_lines(binary)\n",
        "\n",
        "        page_texts = []\n",
        "        for idx, line in enumerate(lines):\n",
        "            txt = recognize_line(line)\n",
        "            page_texts.append(txt)\n",
        "            print(f\"  Line {idx + 1}: {txt}\")\n",
        "\n",
        "        all_page_texts.append(\"\\n\".join(page_texts))\n",
        "    return all_page_texts\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3da060e",
      "metadata": {
        "id": "b3da060e"
      },
      "source": [
        "# STEP 7: Read ground truth from DOCX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "23767d45",
      "metadata": {
        "id": "23767d45"
      },
      "outputs": [],
      "source": [
        "# ------------------------------------------------------\n",
        "# STEP 7: Read ground truth from DOCX\n",
        "# ------------------------------------------------------\n",
        "def read_docx_text(docx_path):\n",
        "    doc = docx.Document(docx_path)\n",
        "    text = \"\\n\".join(p.text.strip() for p in doc.paragraphs if p.text.strip())\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04258da6",
      "metadata": {
        "id": "04258da6"
      },
      "source": [
        "# STEP 8: Evaluate OCR output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "104d812d",
      "metadata": {
        "id": "104d812d"
      },
      "outputs": [],
      "source": [
        "# ------------------------------------------------------\n",
        "# STEP 8: Evaluate OCR output\n",
        "# ------------------------------------------------------\n",
        "def evaluate_text(predicted_text, ground_truth_text):\n",
        "    cer_score = cer(ground_truth_text.lower(), predicted_text.lower())\n",
        "    wer_score = wer(ground_truth_text.lower(), predicted_text.lower())\n",
        "    print(\"\\n==================== OCR EVALUATION ====================\")\n",
        "    print(f\"CER: {cer_score:.4f}\")\n",
        "    print(f\"WER: {wer_score:.4f}\")\n",
        "    print(\"========================================================\")\n",
        "    return cer_score, wer_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y poppler-utils\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGTdjBHmHJfW",
        "outputId": "493acea8-d151-4d48-da3e-015bfffc7435"
      },
      "id": "CGTdjBHmHJfW",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "poppler-utils is already the newest version (22.02.0-2ubuntu0.12).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pdf2image import convert_from_path\n"
      ],
      "metadata": {
        "id": "DofkNNGIHKLW"
      },
      "id": "DofkNNGIHKLW",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "294eeef7",
      "metadata": {
        "id": "294eeef7"
      },
      "source": [
        "# STEP 9: Main execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d664229",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d664229",
        "outputId": "89b61f4a-7709-4488-cb61-e56249265564"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ Starting OCR Pipeline\n",
            "\n",
            "ðŸ“„ Processing Page 1/3 ...\n",
            "  Line 1: I\n",
            "  Line 2: \" 12/25 , \" many\n",
            "  Line 3: 2. 5.\n",
            "  Line 4: 0 0 0 0\n",
            "  Line 5: spares .\n"
          ]
        }
      ],
      "source": [
        "# ------------------------------------------------------\n",
        "# STEP 9: Main execution\n",
        "# ------------------------------------------------------\n",
        "pdf_path = \"15.pdf\"  # input PDF of handwritten answer script\n",
        "gt_path = \"15.docx\"  # ground truth DOCX file\n",
        "\n",
        "print(\"ðŸš€ Starting OCR Pipeline\")\n",
        "page_texts = recognize_pdf(pdf_path)\n",
        "\n",
        "# Combine recognized text\n",
        "recognized_text = \"\\n\\n\".join(page_texts)\n",
        "\n",
        "# Save OCR text\n",
        "with open(\"008_trocr_output.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(recognized_text)\n",
        "print(\"\\nâœ… OCR text saved to 008_trocr_output.txt\")\n",
        "\n",
        "# Load ground truth\n",
        "ground_truth = read_docx_text(gt_path)\n",
        "print(\"\\nâœ… Ground truth loaded from\", gt_path)\n",
        "\n",
        "# Evaluate\n",
        "evaluate_text(recognized_text, ground_truth)\n",
        "\n",
        "# Save final report\n",
        "with open(\"15_TrOCR_comparison_report.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"OCR ACCURACY REPORT (TrOCR - Handwritten)\\n\")\n",
        "    f.write(\"=\" * 60 + \"\\n\")\n",
        "    f.write(recognized_text + \"\\n\\n\")\n",
        "    f.write(\"=\" * 60 + \"\\nGround Truth:\\n\")\n",
        "    f.write(ground_truth)\n",
        "print(\"âœ… Full report saved to 15_TrOCR_comparison_report.txt\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d5045a3",
      "metadata": {
        "id": "5d5045a3"
      },
      "source": [
        "# STEP 10: Additional metrics (BLEU, ROUGE, BERTScore) and reporting\n",
        "\n",
        "This section adds new metric computations and saves results to the requested\n",
        "output folders and an Excel master file. The original code above is left exactly\n",
        "as provided. The cells below add functionality without modifying the original code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b8cd931",
      "metadata": {
        "id": "4b8cd931"
      },
      "outputs": [],
      "source": [
        "# Install additional required packages for BLEU / ROUGE / BERTScore and Excel handling\n",
        "# (This cell is optional if your environment already has these installed)\n",
        "!pip install -q sacrebleu rouge-score bert-score pandas openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa438f3e",
      "metadata": {
        "id": "aa438f3e"
      },
      "outputs": [],
      "source": [
        "# Additional imports for metrics, Excel handling and utilities\n",
        "import re\n",
        "import pandas as pd\n",
        "import sacrebleu\n",
        "from rouge_score import rouge_scorer\n",
        "from bert_score import score as bertscore_score\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf0b1184",
      "metadata": {
        "id": "bf0b1184"
      },
      "outputs": [],
      "source": [
        "# Improved paper number extractor (matches any digit sequence)\n",
        "def extract_paper_number(pdf_path, gt_path):\n",
        "    combined = f\"{pdf_path} {gt_path}\"\n",
        "    m = re.search(r'(\\d+)', combined)   # match 1+ digits\n",
        "    return m.group(1) if m else \"papernumber\"\n",
        "\n",
        "# Compute BLEU, ROUGE-L, BERTScore (returning error rates in percent)\n",
        "def compute_additional_metrics(pred_text, gt_text, bert_lang='en', use_cuda=False):\n",
        "    # BLEU (sacrebleu corpus_bleu expects list of references and list of hypotheses)\n",
        "    bleu = 0.0\n",
        "    rouge_l_f = 0.0\n",
        "    bert_f = 0.0\n",
        "    try:\n",
        "        bleu = sacrebleu.corpus_bleu([pred_text], [[gt_text]]).score  # 0-100\n",
        "    except Exception as e:\n",
        "        print(\"BLEU computation failed:\", e)\n",
        "\n",
        "    bleu_error = 100.0 - float(bleu)\n",
        "\n",
        "    # ROUGE-L (use fmeasure and convert to percent)\n",
        "    try:\n",
        "        scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
        "        rouge_scores = scorer.score(gt_text, pred_text)\n",
        "        rouge_l_f = rouge_scores['rougeL'].fmeasure  # 0-1\n",
        "    except Exception as e:\n",
        "        print(\"ROUGE computation failed:\", e)\n",
        "\n",
        "    rouge_error = 100.0 - (float(rouge_l_f) * 100.0)\n",
        "\n",
        "    # BERTScore (F1 -> percent). Use cuda if available and requested.\n",
        "    try:\n",
        "        device_str = \"cuda\" if use_cuda else \"cpu\"\n",
        "        P, R, F = bertscore_score([pred_text], [gt_text], lang=bert_lang, rescale_with_baseline=True, device=device_str)\n",
        "        # F may be tensor or list-like\n",
        "        f0 = F[0]\n",
        "        bert_f = float(f0.item() if hasattr(f0, \"item\") else f0)\n",
        "    except Exception as e:\n",
        "        print(\"BERTScore computation failed:\", e)\n",
        "\n",
        "    bert_error = 100.0 - (bert_f * 100.0)\n",
        "\n",
        "    return {\n",
        "        'bleu_score': float(bleu),\n",
        "        'bleu_error': float(bleu_error),\n",
        "        'rouge_l_f': float(rouge_l_f),\n",
        "        'rouge_error': float(rouge_error),\n",
        "        'bert_f1': float(bert_f),\n",
        "        'bert_error': float(bert_error)\n",
        "    }\n",
        "\n",
        "# Main wrapper function to compute metrics and save reports & Excel file\n",
        "def generate_all_error_rates(predicted_text, ground_truth_text,\n",
        "                             pdf_path=None, gt_path=None,\n",
        "                             roll_number=None, traditional_model_name=\"Traditional OCR Model\",\n",
        "                             output_root=\"/content/TrOCR_updated_algo\"):\n",
        "    # Choose paper number\n",
        "    papernum_tag = str(roll_number) if roll_number else extract_paper_number(pdf_path or \"\", gt_path or \"\")\n",
        "\n",
        "    # Directories\n",
        "    error_report_dir = Path(output_root) / \"error_report\"\n",
        "    comparison_dir   = Path(output_root) / \"comparison_report\"\n",
        "    output_text_dir  = Path(output_root) / \"output_text\"\n",
        "\n",
        "    # Create dirs\n",
        "    error_report_dir.mkdir(parents=True, exist_ok=True)\n",
        "    comparison_dir.mkdir(parents=True, exist_ok=True)\n",
        "    output_text_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Compute CER and WER via evaluate_text if present\n",
        "    try:\n",
        "        cer_score, wer_score = evaluate_text(predicted_text, ground_truth_text)\n",
        "    except Exception as e:\n",
        "        print(\"evaluate_text failed, recomputing with jiwer:\", e)\n",
        "        from jiwer import wer, cer\n",
        "        cer_score = cer(ground_truth_text.lower(), predicted_text.lower())\n",
        "        wer_score = wer(ground_truth_text.lower(), predicted_text.lower())\n",
        "\n",
        "    # Additional metrics\n",
        "    try:\n",
        "        metrics = compute_additional_metrics(predicted_text, ground_truth_text, use_cuda=torch.cuda.is_available())\n",
        "    except Exception as e:\n",
        "        print(\"compute_additional_metrics failed:\", e)\n",
        "        traceback.print_exc()\n",
        "        metrics = {'bleu_score':0.0,'bleu_error':100.0,'rouge_l_f':0.0,'rouge_error':100.0,'bert_f1':0.0,'bert_error':100.0}\n",
        "\n",
        "    # Paths for outputs\n",
        "    error_report_path = error_report_dir / f\"{papernum_tag}_error_rates.txt\"\n",
        "    trocr_out_path    = output_text_dir / f\"{papernum_tag}_trocr_output.txt\"\n",
        "    comp_path         = comparison_dir / f\"{papernum_tag}_TrOCR_comparison_report.txt\"\n",
        "    excel_path        = error_report_dir / \"error_rates_master.xlsx\"\n",
        "\n",
        "    # Write error report\n",
        "    with open(error_report_path, \"w\", encoding=\"utf-8\") as rf:\n",
        "        rf.write(f\"Paper: {papernum_tag}\\n\")\n",
        "        rf.write(\"=\"*60 + \"\\n\")\n",
        "        rf.write(\"Predicted OCR Text:\\n\\n\")\n",
        "        rf.write(predicted_text + \"\\n\\n\")\n",
        "        rf.write(\"=\"*60 + \"\\nGround Truth:\\n\\n\")\n",
        "        rf.write(ground_truth_text + \"\\n\\n\")\n",
        "        rf.write(\"=\"*60 + \"\\nMETRICS (errors shown as percentages):\\n\\n\")\n",
        "        rf.write(f\"Char Error rate (%): {cer_score*100:.4f}\\n\")\n",
        "        rf.write(f\"Word Error rate (%): {wer_score*100:.4f}\\n\")\n",
        "        rf.write(f\"Bleu Error rate (%): {metrics['bleu_error']:.4f}\\n\")\n",
        "        rf.write(f\"Rouge Error rate (%): {metrics['rouge_error']:.4f}\\n\")\n",
        "        rf.write(f\"Bert Error rate (%): {metrics['bert_error']:.4f}\\n\")\n",
        "\n",
        "    print(f\"âœ… Saved detailed error report to: {error_report_path}\")\n",
        "\n",
        "    # Save TrOCR output\n",
        "    with open(trocr_out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(predicted_text)\n",
        "    print(f\"âœ… Saved TrOCR output to: {trocr_out_path}\")\n",
        "\n",
        "    # Save comparison report\n",
        "    with open(comp_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"OCR ACCURACY REPORT (TrOCR - Handwritten)\\n\")\n",
        "        f.write(\"=\" * 60 + \"\\n\")\n",
        "        f.write(predicted_text + \"\\n\\n\")\n",
        "        f.write(\"=\" * 60 + \"\\nGround Truth:\\n\")\n",
        "        f.write(ground_truth_text + \"\\n\\n\")\n",
        "        f.write(\"=\" * 60 + \"\\nMETRICS (errors shown as percentages):\\n\\n\")\n",
        "        f.write(f\"Char Error rate (%): {cer_score*100:.4f}\\n\")\n",
        "        f.write(f\"Word Error rate (%): {wer_score*100:.4f}\\n\")\n",
        "        f.write(f\"Bleu Error rate (%): {metrics['bleu_error']:.4f}\\n\")\n",
        "        f.write(f\"Rouge Error rate (%): {metrics['rouge_error']:.4f}\\n\")\n",
        "        f.write(f\"Bert Error rate (%): {metrics['bert_error']:.4f}\\n\")\n",
        "\n",
        "    print(f\"âœ… Saved comparison report to: {comp_path}\")\n",
        "\n",
        "    # Prepare row for Excel master\n",
        "    row = {\n",
        "        'Roll Number': papernum_tag,\n",
        "        'Traditional OCR Model': traditional_model_name,\n",
        "        'Word Error rate (%)': wer_score*100,\n",
        "        'Char Error rate (%)': cer_score*100,\n",
        "        'Bleu Error rate (%)': metrics['bleu_error'],\n",
        "        'Rouge Error rate (%)': metrics['rouge_error'],\n",
        "        'Bert Error rate (%)': metrics['bert_error']\n",
        "    }\n",
        "\n",
        "    # Read/append/create Excel safely\n",
        "    try:\n",
        "        if excel_path.exists():\n",
        "            df_master = pd.read_excel(excel_path)\n",
        "            df_master = pd.concat([df_master, pd.DataFrame([row])], ignore_index=True)\n",
        "        else:\n",
        "            df_master = pd.DataFrame([row])\n",
        "        df_master.to_excel(excel_path, index=False)\n",
        "        print(f\"âœ… Excel master saved/updated at: {excel_path}\")\n",
        "    except Exception as e:\n",
        "        print(\"Failed to write Excel master:\", e)\n",
        "        traceback.print_exc()\n",
        "\n",
        "    return {\n",
        "        'cer': cer_score,\n",
        "        'wer': wer_score,\n",
        "        'bleu_score': metrics['bleu_score'],\n",
        "        'bleu_error': metrics['bleu_error'],\n",
        "        'rouge_l_f': metrics['rouge_l_f'],\n",
        "        'rouge_error': metrics['rouge_error'],\n",
        "        'bert_f1': metrics['bert_f1'],\n",
        "        'bert_error': metrics['bert_error'],\n",
        "        'error_report_path': str(error_report_path),\n",
        "        'comparison_report_path': str(comp_path),\n",
        "        'trocr_output_path': str(trocr_out_path),\n",
        "        'excel_path': str(excel_path)\n",
        "    }\n",
        "\n",
        "# ------------------------ CALL the function (ensure recognized_text & ground_truth exist) ------------------------\n",
        "# Replace \"08\" with the paper number you want; this explicit roll_number prevents \"papernumber\" filenames.\n",
        "results = generate_all_error_rates(\n",
        "    predicted_text = recognized_text,\n",
        "    ground_truth_text = ground_truth,\n",
        "    pdf_path = \"15.pdf\",\n",
        "    gt_path = \"15.docx\",\n",
        "    roll_number = \"15\",\n",
        "    traditional_model_name = \"Traditional OCR Model\",\n",
        "    output_root = \"/content/TrOCR_updated_algo\"\n",
        ")\n",
        "\n",
        "# Print saved file locations\n",
        "print(\"\\n=== Saved outputs ===\")\n",
        "print(\"Error report:\", results['error_report_path'])\n",
        "print(\"Comparison report:\", results['comparison_report_path'])\n",
        "print(\"TrOCR output:\", results['trocr_output_path'])\n",
        "print(\"Excel master:\", results['excel_path'])\n",
        "print(\"=====================\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52bdd155",
      "metadata": {
        "id": "52bdd155"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6747f1f",
      "metadata": {
        "id": "e6747f1f"
      },
      "outputs": [],
      "source": [
        "# # STEP 11: Run the extended evaluation (override the original file variables if you wish)\n",
        "# # The original variables in the earlier cell remain unchanged. Here we point to the user's\n",
        "# # ground truth and scanned PDF locations as requested.\n",
        "\n",
        "# # Example: replace '008' with whichever paper number files you have in the specified folders.\n",
        "# pdf_path = \"08.pdf\"  # input PDF of handwritten answer script\n",
        "# gt_path = \"08.docx\"  # ground truth DOCX file\n",
        "\n",
        "# print(\"ðŸš€ Starting extended evaluation (this will call the existing recognize_pdf & read_docx_text functions)\")\n",
        "\n",
        "# # Recognize text using pre-existing recognize_pdf function\n",
        "# page_texts = recognize_pdf(pdf_path)\n",
        "\n",
        "# # Combine recognized text\n",
        "# recognized_text = \"\\n\\n\".join(page_texts)\n",
        "\n",
        "# # Save TrOCR output to the requested folder (the generate_all_error_rates also saves it again)\n",
        "# # But we save a local intermediate copy here as well\n",
        "# local_out = \"008_trocr_output.txt\"\n",
        "# with open(local_out, \"w\", encoding=\"utf-8\") as f:\n",
        "#     f.write(recognized_text)\n",
        "# print(\"\\nâœ… OCR text saved locally to\", local_out)\n",
        "\n",
        "# # Load ground truth (reuse existing function)\n",
        "# ground_truth = read_docx_text(gt_path)\n",
        "# print(\"\\nâœ… Ground truth loaded from\", gt_path)\n",
        "\n",
        "# # Call the combined metric generator (this will create the error_report, excel, comparison, and output_text files)\n",
        "# results = generate_all_error_rates(recognized_text, ground_truth, pdf_path=pdf_path, gt_path=gt_path, traditional_model_name='YourTraditionalOCR')\\\n",
        "\n",
        "# print(\"\\n=== SUMMARY OF GENERATED METRICS ===\")\n",
        "# for k, v in results.items():\n",
        "#     if k.endswith('_path'):\n",
        "#         print(f\"{k}: {v}\")\n",
        "#     else:\n",
        "#         print(f\"{k}: {v}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}